extern "C" {
    fn printString(&[u8]) -> ();
    fn printFloat(f32) -> ();
    fn printDouble(f64) -> ();
    fn printInteger(i32) -> ();
    fn log(f64) -> (f64);
    fn exp(f64) -> (f64);
    fn logf(f32) -> (f32);
    fn lgamma(f64) -> (f64);
    fn randomDouble(f64, f64) -> (f64);
}

fn range(mut b: i32, e: i32, body: fn(i32) -> ()) -> () {
    while b < e {
        body(b++)
    }
}


fn @(?e) range_filter( b: i32, e: i32, body: fn(i32) -> ()) -> (f64) {
    if b < e{
        body(b);
        range_filter(b + 1, e, body);
    }
    0.0
}


fn @(true) max(a: f64, b: f64) -> (f64){
    if a > b{
        a
    }else{
        b
    }
}

fn @(true) relu( x: f64 ) -> (f64){
    if(x>=0.0){
        x
    }else{
        0.1 * x
    }
}

fn @(true) softmax(input: &[f64], output: &mut[f64], size: i32) -> (f64){
  let mut sum = 0.0;
  let mut i = 0;

  while(i < size){
    let e = exp(input(i));
    sum += e;
    output(i) = e;
    i++;
  }

  i = 0;
  while(i < size){
    output(i) = output(i) / sum;
    i++;
  }

  0.0
}

fn @(true) fully_connected(input: &[f64], output: &mut[f64], weights: &[f64], input_size: i32, output_size: i32) -> (f64){
  for i in range_filter(0, output_size){
    let mut value = 0.0;

    for j in range_filter(0,  input_size){
      value += input(j) * weights(j + i * output_size);
    }

    output(i) = relu(value);
  }
  0.0
}

fn runNnBenchmark(file: &[u8]) -> (){
    let size_x = 28;
    let size_y = 28;

    let first_weight_size = size_x*size_y*32;
    let first_weights = ~[first_weight_size:f64];

    let second_weight_size = 32*10;
    let second_weights = ~[second_weight_size:f64];

    for i in range(0, first_weight_size){
        first_weights(i) = randomDouble(-0.1, 0.1);
    }

    for i in range(0, second_weight_size){
        second_weights(i) = randomDouble(-0.1, 0.1);
    }

    let input = ~[size_x*size_y:f64];
    let output = ~[10:f64];

    for i in range(0, 28*28){
        input(i) = randomDouble(0.0, 1.0);
    }

    let label: i32 = 1;

    let Df = rev_diff(loss);
    let (y,pb) = Df(
                (first_weight_size as u64, first_weights),
                (second_weight_size as u64, second_weights),
                ((28*28) as u64, input), label);

    let gradients = pb(1.0);
    let (weights_d_size, weights_d) = gradients(0);
    let (weights_d_2_size, weights_d_2) = gradients(1);

    printString("weights 1");
    for i in range(0, weights_d_size as i32){
        printDouble(weights_d(i));
    }

    for i in range(0, weights_d_2_size as i32){
        printDouble(weights_d_2(i));
    }

    printString("loss");
    printDouble(y);
}

fn @(true) cross_entropy(output: &[f64], target: i32) -> (f64){
  -log(output(target))
}

fn loss(
    first_weights: &[f64],
    second_weights: &[f64],
    input: &[f64],
    target: i32 ) -> (f64){

  let hidden = ~[32:f64];
  let output = ~[10:f64];
  let output_softmax = ~[10:f64];
  fully_connected(input, hidden, first_weights,  28*28, 32);
  fully_connected(hidden, output, second_weights,32, 10);
  softmax(output, output_softmax, 10);
  cross_entropy(output_softmax, target)
}

fn main(argc: i32,argv :&[&[u8]]) -> i32 {
    if argc < 2{
        printString("No Benchmark specified");
    }else{
        let file = argv(1);
        printString(file);
        runNnBenchmark(file);
    }

    0
}


